{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9564669,"sourceType":"datasetVersion","datasetId":5829104},{"sourceId":120002,"sourceType":"modelInstanceVersion","modelInstanceId":100933,"modelId":121027}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-07T13:20:23.235691Z","iopub.execute_input":"2024-10-07T13:20:23.236573Z","iopub.status.idle":"2024-10-07T13:20:23.595473Z","shell.execute_reply.started":"2024-10-07T13:20:23.236535Z","shell.execute_reply":"2024-10-07T13:20:23.594439Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/llama-3.2/transformers/1b-instruct/1/config.json\n/kaggle/input/llama-3.2/transformers/1b-instruct/1/README.md\n/kaggle/input/llama-3.2/transformers/1b-instruct/1/USE_POLICY.md\n/kaggle/input/llama-3.2/transformers/1b-instruct/1/tokenizer.json\n/kaggle/input/llama-3.2/transformers/1b-instruct/1/tokenizer_config.json\n/kaggle/input/llama-3.2/transformers/1b-instruct/1/LICENSE.txt\n/kaggle/input/llama-3.2/transformers/1b-instruct/1/model.safetensors\n/kaggle/input/llama-3.2/transformers/1b-instruct/1/special_tokens_map.json\n/kaggle/input/llama-3.2/transformers/1b-instruct/1/.gitattributes\n/kaggle/input/llama-3.2/transformers/1b-instruct/1/generation_config.json\n/kaggle/input/filtered-data/filtered_combined.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import requests\nfrom PIL import Image\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, AutoProcessor","metadata":{"execution":{"iopub.status.busy":"2024-10-07T13:20:23.597221Z","iopub.execute_input":"2024-10-07T13:20:23.597688Z","iopub.status.idle":"2024-10-07T13:20:40.992706Z","shell.execute_reply.started":"2024-10-07T13:20:23.597650Z","shell.execute_reply":"2024-10-07T13:20:40.991715Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('/kaggle/input/filtered-data/filtered_combined.csv')","metadata":{"execution":{"iopub.status.busy":"2024-10-07T13:20:40.994640Z","iopub.execute_input":"2024-10-07T13:20:40.995373Z","iopub.status.idle":"2024-10-07T13:20:41.039594Z","shell.execute_reply.started":"2024-10-07T13:20:40.995320Z","shell.execute_reply":"2024-10-07T13:20:41.038619Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"model_dir = \"/kaggle/input/llama-3.2/transformers/1b-instruct/1\"\n\n# # Loading the model from the local path\n# model = AutoModelForCausalLM.from_pretrained(\n#     model_dir,\n#     torch_dtype=torch.bfloat16,\n#     device_map=\"auto\",\n#     local_files_only=True\n# )\n\n# # Load the tokenizer from the local path\n# tokenizer = AutoTokenizer.from_pretrained(model_dir, local_files_only=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-07T13:20:41.040755Z","iopub.execute_input":"2024-10-07T13:20:41.041089Z","iopub.status.idle":"2024-10-07T13:21:07.528434Z","shell.execute_reply.started":"2024-10-07T13:20:41.041054Z","shell.execute_reply":"2024-10-07T13:21:07.527561Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# from transformers import pipeline\n\n# pipe = pipeline(\n#     \"text-generation\",\n#     model=model,\n#     tokenizer=tokenizer,\n#     torch_dtype=torch.bfloat16,\n#     device_map=\"auto\",\n# )","metadata":{"execution":{"iopub.status.busy":"2024-10-07T13:21:07.530344Z","iopub.execute_input":"2024-10-07T13:21:07.530654Z","iopub.status.idle":"2024-10-07T13:21:08.058818Z","shell.execute_reply.started":"2024-10-07T13:21:07.530621Z","shell.execute_reply":"2024-10-07T13:21:08.057832Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# messages = [\n#     {\"role\" : \"system\", \"content\": f\"You are good at creating a synthetic dataset which resembles human like mindset for the pandas dataset {df}. This dataset has the following columns:- rating,review_title,text,asin,parent_asin,user_id,timestamp,helpful_vote,verified_purchase,date,time,product_title,categories,cat1.\"},\n#     {\"role\" : \"user\", \"content\" : \"Generate 50 synthetic data rows in pandas dataframe format.\"}\n# ]\n\n# outputs = pipe(\n#     messages,\n#     max_new_tokens=3000,\n# )\n\n# print(outputs[0][\"generated_text\"][-1])","metadata":{"execution":{"iopub.status.busy":"2024-10-07T13:21:08.060007Z","iopub.execute_input":"2024-10-07T13:21:08.060716Z","iopub.status.idle":"2024-10-07T13:22:40.838423Z","shell.execute_reply.started":"2024-10-07T13:21:08.060670Z","shell.execute_reply":"2024-10-07T13:22:40.837472Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\nStarting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n","output_type":"stream"},{"name":"stdout","text":"{'role': 'assistant', 'content': \"Here's a Python code snippet that generates 50 synthetic data rows in pandas DataFrame format:\\n\\n```python\\nimport pandas as pd\\nimport numpy as np\\n\\n# Set a seed for reproducibility\\nnp.random.seed(42)\\n\\n# Define the columns\\ncolumns = ['rating','review_title', 'text', 'asin', 'parent_asin', 'user_id', 'timestamp', 'helpful_vote','verified_purchase', 'date', 'time', 'product_title', 'categories', 'cat1']\\n\\n# Generate 50 synthetic data rows\\ndata = {\\n    'rating': np.random.randint(1, 6, 50),\\n   'review_title': np.random.choice(['Aweful smell', 'Strong smell & less effective', 'Solves a LOT of problems', 'Different Packaging', 'Stopped after taking it for 3 days because it...', 'Didnâ€™t taste good', 'Product is not in edible condition!'], 50),\\n    'text': np.random.choice(['It looks like the product sent is comparable,...', 'These smelled so bad and tasted so bad that I...', 'I use L-methionine to lower my dog\\\\'s urinary p...', 'If you know what this does, you know why it\\\\'s...', 'It\\\\'s not for me.  I didn\\\\'t take this long enou...', 'My 5 year old refuses to take it as she said i...', 'This is what it looked like when hem I opened...', 'Should have a negative rating choice! Upon ope...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to a healthy 95 year olds...', 'This is an addition to\"}\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import pipeline\nimport random\n# Loading the model from the local path\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_dir,\n    torch_dtype=torch.bfloat16,\n    device_map=\"auto\",\n    local_files_only=True)\n\n# Loading the tokenizer from the local path\ntokenizer = AutoTokenizer.from_pretrained(model_dir, local_files_only=True)\n\npipe = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    torch_dtype=torch.bfloat16,\n    device_map=\"auto\",\n)\n\ndef generate_synthetic_data(prompt, max_length):\n    outputs = pipe(\n        prompt,\n        max_new_tokens=max_length,\n        temperature=0.5,\n        pad_token_id=pipe.tokenizer.eos_token_id\n    )\n\n    # Return the generated text\n    return (outputs[0][\"generated_text\"]).replace(prompt, \"\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_synthetic_reviews(num_reviews=30):\n    data = []\n    for i in range(num_reviews):\n        # Generate the individual fields using LLaMA prompts\n        product_title_prompt = f\"Choose any row value of {df['product_title'].iloc[num_reviews]} . Just tell a single name of the product title from the given dataframe. Do not write anything extra. Be precise.\"\n        product_title = generate_synthetic_data(product_title_prompt, max_length=50)\n        \n        text_prompt = f\"Write a brief product review for a product {product_title} as if you were a human. Do not put the rating in  this.\"\n        review_text = generate_synthetic_data(text_prompt, max_length=100)\n        \n        review_title_prompt = f\"Generate a product review title for the product having title {product_title}. It should be to the point and point out the summary in fewer words of {review_text}.\"\n        review_title = generate_synthetic_data(review_title_prompt, max_length=15)\n        \n        rating_prompt = f\"Based on the review given, which is {review_text}, give a single numerical value which could be any integer value ranging from 1 to 5.\"\n        rating = generate_synthetic_data(rating_prompt, max_length=len(rating_prompt)+2)\n\n        asin = \"B0\" + ''.join([random.choice(\"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\") for _ in range(8)])\n        parent_asin = asin  # Keep asin and parent_asin mostly the same\n        user_id = ''.join([random.choice(\"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\") for _ in range(28)])\n        \n        timestamp_prompt = \"Suggest a numerical value for a timestamp in the format MM/DD/YYYY HH:MM:SS AM/PM. For example, '10/3/2012 1:48:18 AM'. Do not give extra information like steps for calculation!\"\n        timestamp = generate_synthetic_data(timestamp_prompt, max_length=200)\n        \n        helpful_vote = random.randint(0, 50)\n        verified_purchase = random.choice([True, False])\n        \n        date_prompt = \"Choose a random date in the format MM/DD/YYYY. For example, '10/3/2012'. Do not give any python code as output. Only date is required. Do not give extra information like steps for calculation!\"\n        date = generate_synthetic_data(date_prompt, max_length=200)\n        \n        time_prompt = \"Choose a random time in the format HH:MM in 24-hour format. For example, '16:06'. Don't give any python code as output. Only time is required. Do not give extra information like steps for calculation!\"\n        time = generate_synthetic_data(time_prompt, max_length=200)\n\n        # Random categories and subcategory\n        categories = \"Health & Household\"\n        cat1 = \"Vitamins & Supplements\"\n        print(i)\n        # Append the generated data to the list\n        data.append({\n            \"rating\": rating,\n            \"review_title\": review_title,\n            \"text\": review_text,\n            \"asin\": asin,\n            \"parent_asin\": parent_asin,\n            \"user_id\": user_id,\n            \"timestamp\": timestamp,\n            \"helpful_vote\": helpful_vote,\n            \"verified_purchase\": verified_purchase,\n            \"date\": date,\n            \"time\": time,\n            \"product_title\": product_title,\n            \"categories\": categories,\n            \"cat1\": cat1\n        })\n    \n    # Creating the synthetic DataFrame\n    df_synthetic = pd.DataFrame(data)\n    return df_synthetic\n\n# Generating 50 synthetic reviews\ndf_synthetic = generate_synthetic_reviews(num_reviews=50)\ndf_synthetic.to_csv(\"/kaggle/working/synthetic_reviews_llama.csv\", index=False)\n\n# Print confirmation message\nprint(\"Synthetic dataset generated and saved as 'synthetic_reviews_llama_1b.csv'.\")","metadata":{},"execution_count":null,"outputs":[]}]}